{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SpKvHUQUXFnk"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2_ZpxKPidHS2"
      },
      "outputs": [],
      "source": [
        "batch_size = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TfBqZepwcB6O",
        "outputId": "c8603ae8-b4ae-4540-a92e-06a60ebf6087"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "trainset = torchvision.datasets.CIFAR10('cifar',\n",
        "            train=True, download=True,\n",
        "            transform=torchvision.transforms.Compose([\n",
        "                torchvision.transforms.Resize((32, 32)),\n",
        "                torchvision.transforms.ToTensor(),\n",
        "                torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "            ]))\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10('cifar',\n",
        "            train=False, download=True,\n",
        "            transform=torchvision.transforms.Compose([\n",
        "                torchvision.transforms.Resize((32, 32)),\n",
        "                torchvision.transforms.ToTensor(),\n",
        "                torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "            ]))\n",
        "\n",
        "trainset = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
        "testset = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "train_dataset = iter(trainset)\n",
        "test_dataset = iter(testset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Iec12MZveYDd"
      },
      "outputs": [],
      "source": [
        "def ResidualBlock(channel):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_channels=channel, out_channels=channel, kernel_size=3, padding=1),\n",
        "        nn.BatchNorm2d(channel),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Conv2d(in_channels=channel, out_channels=channel, kernel_size=3, padding=1),\n",
        "        nn.BatchNorm2d(channel),\n",
        "        nn.ReLU(inplace=True)\n",
        "    )\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(ResNet, self).__init__()\n",
        "    self.layer0 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=3, out_channels=64, kernel_size=7, stride=2, padding=3),\n",
        "        nn.BatchNorm2d(64),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "    self.layerfc = nn.Sequential(\n",
        "        nn.AdaptiveAvgPool2d((1, 1)),\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features=512, out_features=10)\n",
        "    )\n",
        "    self.layer1 = ResidualBlock(64)\n",
        "    self.layer2 = ResidualBlock(128)\n",
        "    self.layer3 = ResidualBlock(256)\n",
        "    self.layer4 = ResidualBlock(512)\n",
        "    self.activation = nn.ReLU()\n",
        "    self.convert2 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
        "        nn.BatchNorm2d(128),\n",
        "        nn.ReLU(inplace=True))\n",
        "    self.convert3 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
        "        nn.BatchNorm2d(256),\n",
        "        nn.ReLU(inplace=True))\n",
        "    self.convert4 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1),\n",
        "        nn.BatchNorm2d(512),\n",
        "        nn.ReLU(inplace=True))\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.layer0(x)\n",
        "\n",
        "    x = self.layer1(x) + x\n",
        "\n",
        "    tmp1 = self.convert2(x)\n",
        "    tmp2 = self.layer2(tmp1)\n",
        "    x = tmp1 + tmp2\n",
        "    \n",
        "    tmp1 = self.convert3(x)\n",
        "    tmp2 = self.layer3(tmp1)\n",
        "    x = tmp1 + tmp2\n",
        "\n",
        "    tmp1 = self.convert4(x)\n",
        "    tmp2 = self.layer4(tmp1)\n",
        "    x = tmp1 + tmp2\n",
        "\n",
        "    x = self.layerfc(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRgGHrjdiVH2",
        "outputId": "9d1bbb05-a082-4036-8864-06da0e52d33e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 1, loss: 1.3981024026870728, acc: 0.4554\n",
            "epoch: 2, loss: 1.2791693210601807, acc: 0.5377\n",
            "epoch: 3, loss: 0.7110854387283325, acc: 0.6587\n",
            "epoch: 4, loss: 0.6633554100990295, acc: 0.7077\n",
            "epoch: 5, loss: 0.5661798119544983, acc: 0.759\n",
            "epoch: 6, loss: 0.7514356970787048, acc: 0.7488\n",
            "epoch: 7, loss: 0.5353270769119263, acc: 0.7792\n",
            "epoch: 8, loss: 0.5380469560623169, acc: 0.7815\n",
            "epoch: 9, loss: 0.2961450517177582, acc: 0.7799\n",
            "epoch: 10, loss: 0.2953492999076843, acc: 0.811\n",
            "epoch: 11, loss: 0.25534293055534363, acc: 0.8514\n",
            "epoch: 12, loss: 0.16899806261062622, acc: 0.8503\n",
            "epoch: 13, loss: 0.20900793373584747, acc: 0.8513\n",
            "epoch: 14, loss: 0.04431191831827164, acc: 0.8488\n",
            "epoch: 15, loss: 0.08536839485168457, acc: 0.8484\n",
            "epoch: 16, loss: 0.16057142615318298, acc: 0.8486\n",
            "epoch: 17, loss: 0.10420699417591095, acc: 0.8486\n",
            "epoch: 18, loss: 0.07933694124221802, acc: 0.8426\n",
            "epoch: 19, loss: 0.04908553510904312, acc: 0.8424\n",
            "epoch: 20, loss: 0.04525141045451164, acc: 0.8427\n",
            "epoch: 21, loss: 0.02319737896323204, acc: 0.8472\n",
            "epoch: 22, loss: 0.0179610475897789, acc: 0.8464\n",
            "epoch: 23, loss: 0.0103285051882267, acc: 0.8452\n",
            "epoch: 24, loss: 0.026464398950338364, acc: 0.845\n",
            "epoch: 25, loss: 0.01019771583378315, acc: 0.8446\n",
            "epoch: 26, loss: 0.013521967455744743, acc: 0.8467\n",
            "epoch: 27, loss: 0.016854960471391678, acc: 0.8429\n",
            "epoch: 28, loss: 0.006194102577865124, acc: 0.8454\n",
            "epoch: 29, loss: 0.030684303492307663, acc: 0.8461\n",
            "epoch: 30, loss: 0.01941247656941414, acc: 0.8444\n",
            "epoch: 31, loss: 0.005051744170486927, acc: 0.8436\n",
            "epoch: 32, loss: 0.014986696653068066, acc: 0.8451\n",
            "epoch: 33, loss: 0.00856751948595047, acc: 0.8441\n",
            "epoch: 34, loss: 0.023176226764917374, acc: 0.8437\n",
            "epoch: 35, loss: 0.011047979816794395, acc: 0.8445\n",
            "epoch: 36, loss: 0.01123013161122799, acc: 0.8449\n",
            "epoch: 37, loss: 0.007534203585237265, acc: 0.8435\n",
            "epoch: 38, loss: 0.009159513749182224, acc: 0.8439\n",
            "epoch: 39, loss: 0.005461926572024822, acc: 0.8445\n",
            "epoch: 40, loss: 0.007291548885405064, acc: 0.8432\n",
            "epoch: 41, loss: 0.012033140286803246, acc: 0.8444\n",
            "epoch: 42, loss: 0.009108984842896461, acc: 0.8452\n",
            "epoch: 43, loss: 0.0031284720171242952, acc: 0.8431\n",
            "epoch: 44, loss: 0.005836641415953636, acc: 0.8432\n",
            "epoch: 45, loss: 0.010150725021958351, acc: 0.8437\n",
            "epoch: 46, loss: 0.003695025574415922, acc: 0.8436\n",
            "epoch: 47, loss: 0.010310024954378605, acc: 0.8459\n",
            "epoch: 48, loss: 0.013586427085101604, acc: 0.8425\n",
            "epoch: 49, loss: 0.014156592078506947, acc: 0.843\n",
            "epoch: 50, loss: 0.0205700546503067, acc: 0.8438\n"
          ]
        }
      ],
      "source": [
        "model = ResNet()\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "def optim_scheduler(epoch):\n",
        "  if epoch < 10:\n",
        "    lr = 1e-3\n",
        "  elif epoch < 20:\n",
        "    lr = 1e-4\n",
        "  else:\n",
        "    lr = 1e-5\n",
        "  return torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "loss_list = []\n",
        "acc_list = []\n",
        "\n",
        "for epoch in range(50):\n",
        "  optimizer = optim_scheduler(epoch)\n",
        "  for idx, (x, label) in enumerate(trainset):\n",
        "    x, label = x.to(device), label.to(device)\n",
        "    model.train()\n",
        "    logits = model(x)\n",
        "    loss = criterion(logits, label)\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "        \n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "      tot_corr = 0\n",
        "      tot_num = 0\n",
        "      \n",
        "      for x, label in testset:\n",
        "          x, label = x.to(device), label.to(device)\n",
        "          logits = model(x)\n",
        "          pred = logits.argmax(dim=1)\n",
        "          \n",
        "          tot_corr += torch.eq(pred, label).float().sum().item()\n",
        "          tot_num += x.size(0)\n",
        "      acc = tot_corr / tot_num\n",
        "      \n",
        "  loss_list.append(loss.item())\n",
        "  acc_list.append(acc)\n",
        "    \n",
        "  print('epoch: {}, loss: {}, acc: {}'.format(epoch+1, loss, acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YJC8SL1kJhAA"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
